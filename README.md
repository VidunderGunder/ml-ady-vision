# MLAdy Vision <!-- omit in toc -->

All things related to vision ğŸ‘€

![vision](docs/vision.jpg)

## Table of Contents <!-- omit in toc -->

- [Vision (All modules combined)](#vision-all-modules-combined)
- [Detection (module) ğŸ”](#detection-module-)
  - [Quick Start ğŸš€](#quick-start-)
- [Depth (module) ğŸ¤½â€â™‚ï¸](#depth-module-ï¸)
  - [Quick Start ğŸš€](#quick-start--1)

## Vision (All modules combined)

_TODO: Combine detection and depth_

## Detection (module) ğŸ”

[YOLOv5](https://github.com/ultralytics/yolov5) with custom training to detect trash

See `train_trash_detection.ipynb` for training

Datasets used for training:

- [TACO](http://tacodataset.org/)

### Quick Start ğŸš€

Clone [YOLOv5](https://github.com/ultralytics/yolov5) inside `ml-ady-vision`

```shell
git clone https://github.com/ultralytics/yolov5
```

Go into the `yolov5` folder

```shell
cd yolov5
```

Install requirements

```shell
pip install -r requirements.txt
```

Run inference

```shell
python detect.py --source "../input/trash.jpg" --weights "../detection_weights.pt" --img-size 640 --conf 0.675 --exist-ok --project ../ --name output
```

Export ONNX-model

```shell
python models/export.py --weights "../detection_weights.pt" --img 640 --batch 1
```

## Depth (module) ğŸ¤½â€â™‚ï¸

[AdaBins](https://github.com/shariqfarooq123/AdaBins) with pretrained models to estimate depth map

Datasets used for training:

- [KITTI](http://www.cvlibs.net/datasets/kitti/eval_depth_all.php) *outdoors*
- [NYU](https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html) *indoors*


### Quick Start ğŸš€

Install [CUDA](https://developer.nvidia.com/cuda-toolkit-archive) (tested on 10.2)

Install [cuDNN](https://developer.nvidia.com/rdp/cudnn-download) (tested on 8.0.5 for CUDA 10.2)

Install [Anaconda](https://www.anaconda.com/products/individual)

Create virtual environment (tested on python 3.6.6)

```shell
conda create -n vision python=3.6.6 anaconda
```

Install PyTorch (tested on 1.7.0 and 1.7.1)

```shell
conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch
```

See [get started](https://pytorch.org/get-started/locally/) if not following previous recommendations, as you may want another version of PyTorch.

Install Taqaddum

```shell
conda install -c conda-forge tqdm
```

Run the setup

```shell
setup_depth.sh
```

[Download pretrained weights](https://drive.google.com/drive/folders/1nYyaQXOBjNdUJDsmJpcRpu6oE55aQoLA?usp=sharing)

Place pretrained weights in `pretrained/`

Test depth inference

```shell
python depth.py
```
